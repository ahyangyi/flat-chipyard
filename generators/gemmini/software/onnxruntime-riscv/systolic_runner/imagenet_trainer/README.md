# Imagenet Trainer

Here we provide a trainer for resnet50 models (although much like the inference counterpart, this should be generalizable to any imagenet-type model). Models to be trained can be acquired in two ways: from the model zoo (pre-trained and thus good for verifying accuracy), or by exporting from pytorch.

Note that depending on which model you run, you will have you change the image preprocessing code inside `trainer.cpp`. You might also have to change the input/output names (feed/fetch names) in there as well if you're trying to adapt it for a different model.

## From model zoo

If you use the pre-trained resnet50 model from the model zoo, you'll want to increase the batch size


```
model = onnx.load("resnet50_inf.onnx")
[p for p, val in enumerate(model.graph.initializer) if val.name == "OC2_DUMMY_1"]
from onnx import numpy_helper
numpy_helper.to_array(model.graph.initializer[268])
x = numpy_helper.to_array(model.graph.initializer[268])
x = x.copy()
x[0] = 10
model.graph.initializer[268].raw_data = numpy_helper.from_array(x).raw_data
model.graph.output[0].type.tensor_type.shape.dim[0].dim_value = 10
model.graph.input[0].type.tensor_type.shape.dim[0].dim_value = 10
onnx.save(model, "resnet50_zoo_dynamic.onnx")
```

Above we increase batch-size to 10. Be sure that you use the same batch size parameter flag when training.

As this model is pre-trained, you might want to manually modify some of the weights in the proto.


## From Pytorch

Resnet50 models can also be exported from pytorch (either pre-trained from torchvision repo or a model with randomly initialized weights). Be sure to export the model with variable batch dimension:

```
import torch
import torchvision
model = torchvision.models.resnet50(pretrained=True)
batch_size = 1    # just a random number
x = torch.randn(batch_size, 3, 224, 224, requires_grad=True)
torch.onnx.export(model, x, "resnet50.onnx", opset_version=12, do_constant_folding=False, training=torch.onnx.TrainingMode.TRAINING, input_names = ['gpu_0/data_0'], output_names = ['gpu_0/softmax_1'], dynamic_axes={'gpu_0/data_0' : {0 : 'batch_size'}, 'gpu_0/softmax_1' : {0 : 'batch_size'}})
```

Note that I'm not sure the preprocessing for pytorch models is correct.

## Running


```
qemu resnet_train --model_name model/resnet50.onnx  --train_data_txt batch_out.txt --num_train_steps 1 --train_batch_size 10 -x 0 -d 0 -O 0
```

Where `train_data_txt` is generated by the batch preprocess script found in the resnet50 inference runner folder. Note that by default half the images will be used for training, and half will be used for the final evaluation. You can change the number of images that are considered by using `--num_samples`.
